<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://unpkg.com/face-api.js"></script> 
    <style>
        /* CSS styles (omitted for brevity) */
    </style>
</head>
<body>
    <h1>Face Recognition</h1>
    <p id="status">Loading models...</p>

    <div id="input-container">
        <input type="file" id="imageInput" accept="image/*">
        <p>Upload an image to test the model</p>
        <img id="preview" src="" alt="Image Preview">
    </div>

    <div id="result">
        <h2>Prediction:</h2>
        <p id="prediction" class="loading">No prediction yet</p>
    </div>

    <canvas id="overlay"></canvas> 

    <script>
        const modelURL = 'https://cdn.jsdelivr.net/npm/face-api.js/dist/'; // Example CDN
        const knownFaceEmbeddings = [ 
            /* Replace with actual known face descriptors */
        ];
        const knownPersonNames = ['Person 1', 'Person 2']; // Corresponding names

        let faceMatcher;

        async function loadModels() {
            try {
                await faceapi.loadSsdMobilenetv1Model(modelURL);
                await faceapi.loadFaceLandmarkModel(modelURL);
                await faceapi.loadFaceRecognitionModel(modelURL);
                console.log('Models loaded successfully');
                document.getElementById('status').innerText = 'Models loaded successfully!';

                faceMatcher = new faceapi.FaceMatcher(knownFaceEmbeddings, knownPersonNames, 0.6); 
            } catch (error) {
                console.error('Error loading models:', error);
                document.getElementById('status').innerText = 'Failed to load models. Check model URLs.';
            }
        }

        loadModels();

        document.getElementById('imageInput').addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file) return;

            const preview = document.getElementById('preview');
            preview.src = URL.createObjectURL(file);

            preview.onload = async () => { 
                const canvas = document.getElementById('overlay');
                faceapi.matchDimensions(canvas, preview); 

                try {
                    const detections = await faceapi.detectAllFaces(preview)
                        .withFaceLandmarks()
                        .withFaceDescriptors();

                    console.log('Detections:', detections); // Log detections
                    if (detections.length > 0) {
                        const faceDescriptors = detections.map(d => d.descriptor);
                        console.log('Face Descriptors:', faceDescriptors); // Log descriptors

                        const results = faceDescriptors.map(descriptor => {
                            const bestMatch = faceMatcher.findBestMatch(descriptor);
                            return `${bestMatch.label} (distance: ${bestMatch.distance})`;
                        });

                        document.getElementById('prediction').innerHTML = results.join('<br>');
                    } else {
                        document.getElementById('prediction').innerText = 'No faces detected.';
                    }

                    faceapi.draw.drawDetections(canvas, detections); 
                    faceapi.draw.drawFaceLandmarks(canvas, detections); 

                } catch (error) {
                    console.error('Error during prediction:', error);
                    document.getElementById('prediction').innerText = `Prediction failed: ${error.message}`; 
                }
            };
        });
    </script>
</body>
</html>
